# üìì Jupyter Notebooks - Monitor de Precios SIPC

Este directorio contiene los notebooks Jupyter utilizados para el an√°lisis de datos del proyecto Monitor de Precios SIPC.

## üóÇÔ∏è Estructura de Notebooks

### 01_exploracion.ipynb
**An√°lisis Exploratorio de Datos (EDA)**

- **Objetivo:** Explorar y entender los datos raw del Data Lake
- **Datos utilizados:** `data_sipc/raw/` (precios, productos, establecimientos)
- **Contenido:**
  - Carga y visualizaci√≥n inicial de datos
  - Estad√≠sticas descriptivas
  - Distribuciones temporales y geogr√°ficas
  - An√°lisis de calidad de datos (nulos, duplicados)
  - Verificaci√≥n de integridad referencial
  - An√°lisis cruzado de precios por categor√≠a
- **Duraci√≥n estimada:** 10-15 minutos

### 02_modelo_datos.ipynb
**Documentaci√≥n del Modelo Dimensional**

- **Objetivo:** Explicar y validar el Star Schema implementado
- **Datos utilizados:** `data_sipc/refined/` (dimensiones y tabla de hechos)
- **Contenido:**
  - Arquitectura del modelo (diagrama conceptual)
  - Descripci√≥n detallada de cada dimensi√≥n
  - Tabla de hechos y medidas
  - Validaci√≥n de integridad referencial
  - Ejemplos de consultas anal√≠ticas
  - Benchmark de performance
- **Duraci√≥n estimada:** 15-20 minutos

### 03_dashboard.ipynb
**Dashboard de M√©tricas de Negocio**

- **Objetivo:** Visualizar y analizar las 6 m√©tricas principales
- **Datos utilizados:** `data_sipc/exports_dashboard/` (m√©tricas pre-calculadas)
- **Contenido:**
  - **M√©trica 1:** Precio promedio por producto
  - **M√©trica 2:** Variaci√≥n porcentual mensual
  - **M√©trica 3:** Precio m√≠nimo y m√°ximo
  - **M√©trica 4:** Costo de canasta b√°sica por supermercado
  - **M√©trica 5:** √çndice de dispersi√≥n de precios
  - **M√©trica 6:** Ranking de supermercados
  - An√°lisis integrado y correlaciones
  - Conclusiones y recomendaciones
- **Duraci√≥n estimada:** 20-30 minutos

---

## üöÄ C√≥mo Ejecutar los Notebooks

### Requisitos Previos

1. **Pipeline ETL ejecutado:** Los notebooks requieren que el pipeline de Airflow haya procesado los datos
2. **Jupyter Lab activo:** El contenedor Docker `jupyter` debe estar corriendo

### Paso 1: Iniciar el Entorno

```bash
# Desde el directorio ra√≠z del proyecto
docker-compose up -d
```

Esto inicia:
- Contenedor `airflow` (con el DAG de ETL)
- Contenedor `jupyter` (Jupyter Lab con PySpark)

### Paso 2: Acceder a Jupyter Lab

1. Abrir navegador en: **http://localhost:8888**
2. Navegar a la carpeta `notebooks/`

### Paso 3: Ejecutar los Notebooks

**Orden recomendado:**

```
01_exploracion.ipynb ‚Üí 02_modelo_datos.ipynb ‚Üí 03_dashboard.ipynb
```

**Ejecuci√≥n:**
- Usar `Shift + Enter` para ejecutar celda por celda
- O desde el men√∫: `Run ‚Üí Run All Cells`

---

## üìä Datos Utilizados

### Rutas Relativas en Notebooks

Los notebooks utilizan rutas relativas desde `notebooks/`:

```python
# Ejemplo: cargar datos raw
df = spark.read.parquet('../data_sipc/raw/precios.parquet')

# Ejemplo: cargar datos refined
df = spark.read.parquet('../data_sipc/refined/dim_tiempo.parquet')

# Ejemplo: cargar m√©tricas
df = pd.read_parquet('../data_sipc/exports_dashboard/precio_promedio.parquet')
```

### Verificar Disponibilidad de Datos

Antes de ejecutar, verificar que existen:

```bash
ls -lh data_sipc/raw/
ls -lh data_sipc/refined/
ls -lh data_sipc/exports_dashboard/
```

Si faltan datos, ejecutar el DAG de Airflow:

```bash
# Opci√≥n 1: Desde UI de Airflow (http://localhost:8080)
# Trigger manual del DAG "monitor_precios_sipc_etl"

# Opci√≥n 2: Desde l√≠nea de comandos
docker exec airflow airflow dags trigger monitor_precios_sipc_etl
```

---

## üé® Visualizaciones

Los notebooks incluyen m√∫ltiples visualizaciones:

- **üìà Gr√°ficos de l√≠neas:** Evoluci√≥n temporal de precios
- **üìä Histogramas:** Distribuci√≥n de precios y variaciones
- **üì¶ Boxplots:** Comparaci√≥n de dispersi√≥n
- **üéØ Scatter plots:** Correlaciones entre m√©tricas
- **üèÜ Gr√°ficos de barras:** Rankings y comparaciones

**Librer√≠as utilizadas:**
- `matplotlib` - Gr√°ficos est√°ticos
- `seaborn` - Visualizaciones estad√≠sticas mejoradas
- `pandas` - Manipulaci√≥n de datos para gr√°ficos

---

## üõ†Ô∏è Soluci√≥n de Problemas

### Error: "No module named 'pyspark'"

**Causa:** Ejecutando notebook fuera del contenedor Docker

**Soluci√≥n:**
```bash
# Acceder a Jupyter Lab dentro del contenedor
http://localhost:8888
```

### Error: "FileNotFoundError: [Errno 2] No such file or directory"

**Causa:** Datos no generados por el pipeline

**Soluci√≥n:**
```bash
# Ejecutar pipeline de Airflow primero
docker exec airflow airflow dags trigger monitor_precios_sipc_etl

# Esperar a que complete (~6 minutos)
docker exec airflow airflow dags list-runs -d monitor_precios_sipc_etl
```

### Kernel muere o se queda sin memoria

**Causa:** Datasets grandes pueden consumir mucha memoria

**Soluci√≥n:**
- Reiniciar kernel: `Kernel ‚Üí Restart Kernel`
- Ejecutar celdas en orden (no ejecutar todas a la vez)
- Usar `.sample()` en DataFrames de PySpark para pruebas

---

## üìù Notas Importantes

### Diferencias entre Notebooks y Pipeline ETL

- **Notebooks:** Usan rutas relativas (`../data_sipc/`)
- **Pipeline Airflow:** Usa rutas absolutas (`/opt/airflow/data_sipc/`)

### Modo de Spark

Los notebooks usan Spark en **modo local**:

```python
spark = SparkSession.builder \
    .appName("MyApp") \
    .master("local[*]") \  # Todos los cores locales
    .getOrCreate()
```

### Persistencia de Resultados

Los notebooks **NO modifican** los datos del Data Lake. Solo leen y visualizan.

Para regenerar m√©tricas, ejecutar el DAG de Airflow.

---

## üìö Referencias

- **Star Schema Design:** [Kimball Dimensional Modeling](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/)
- **PySpark Documentation:** [Apache Spark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)
- **SIPC Data Source:** [Cat√°logo de Datos Abiertos Uruguay](https://catalogodatos.gub.uy/)

---

## ‚úÖ Checklist de Ejecuci√≥n

Antes de presentar, verificar:

- [ ] Pipeline ETL ejecutado exitosamente
- [ ] Todos los archivos Parquet generados en `exports_dashboard/`
- [ ] Notebooks ejecutados sin errores
- [ ] Visualizaciones renderizadas correctamente
- [ ] M√©tricas calculadas con valores coherentes
- [ ] Conclusiones y recomendaciones revisadas

---

**√öltima actualizaci√≥n:** Diciembre 2024  
**Autor:** Equipo Monitor de Precios SIPC - UCU Campus Salto
