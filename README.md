# Monitor de Precios SIPC

**Proyecto del curso Big Data** â€“ Universidad CatÃ³lica del Uruguay (Campus Salto)

Pipeline ETL orquestado con **Apache Airflow** para analizar datos de precios del **SIPC** (Sistema de InformaciÃ³n de Precios al Consumidor) de Uruguay. Construye un Data Lake con modelo dimensional (Star Schema) y calcula indicadores econÃ³micos clave.

---

## ðŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitectura](#-arquitectura)
- [Requisitos](#-requisitos)
- [InstalaciÃ³n y Uso](#-instalaciÃ³n-y-uso)
- [Pipeline ETL](#-pipeline-etl)
- [Modelo de Datos](#-modelo-de-datos)
- [MÃ©tricas de Negocio](#-mÃ©tricas-de-negocio)
- [Notebooks](#-notebooks)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Desarrollo](#-desarrollo)
- [SoluciÃ³n de Problemas](#-soluciÃ³n-de-problemas)
- [Referencias](#-referencias)

---

## âœ¨ CaracterÃ­sticas

- **Data Lake** con 4 zonas: Landing â†’ Raw â†’ Refined â†’ Exports
- **Star Schema** con 4 dimensiones y 1 tabla de hechos (20M+ registros)
- **6 mÃ©tricas de negocio** pre-calculadas para anÃ¡lisis
- **OrquestaciÃ³n** automatizada con Apache Airflow
- **Visualizaciones** interactivas en Jupyter Notebooks
- **Dockerizado** para reproducibilidad

---

## ðŸ— Arquitectura

### Data Lake (filesystem local)

```
data_sipc/
â”œâ”€â”€ landing/           # CSV originales del SIPC
â”œâ”€â”€ raw/               # Parquet limpio y tipado
â”œâ”€â”€ refined/           # Modelo estrella (dimensiones + hechos)
â””â”€â”€ exports_dashboard/ # MÃ©tricas para visualizaciÃ³n
```

### Stack TecnolÃ³gico

| Componente | TecnologÃ­a | DescripciÃ³n |
|------------|------------|-------------|
| ETL | PySpark | Transformaciones en modo `local[*]` |
| OrquestaciÃ³n | Airflow 2.9.2 | SequentialExecutor + SQLite |
| Contenedores | Docker Compose | Servicios `airflow` y `jupyter` |
| Almacenamiento | Parquet | Formato columnar optimizado |

---

## ðŸ“¦ Requisitos

### Sistema

- **Docker** 20.10+
- **Docker Compose** 2.0+
- **RAM** 4GB mÃ­nimo (6GB recomendado)
- **Disco** 5GB disponible

### Datos

Archivos CSV del SIPC (descargar de [CatÃ¡logo de Datos Abiertos](https://catalogodatos.gub.uy/)):
- `precios.csv` (~20M+ registros)
- `productos.csv` (~379 productos)
- `establecimientos.csv` (~852 establecimientos)

---

## ðŸš€ InstalaciÃ³n y Uso

### 1. Clonar el repositorio

```bash
git clone https://github.com/clara-s-n/monitor-precios-sipc.git
cd monitor-precios-sipc
```

### 2. Preparar datos de entrada

Colocar los archivos CSV del SIPC en la carpeta `data_sipc/landing/`:

```
data_sipc/landing/
â”œâ”€â”€ precios.csv
â”œâ”€â”€ productos.csv
â””â”€â”€ establecimientos.csv
```

### 3. Iniciar los servicios

```bash
docker-compose up -d
```

### 4. Verificar estado

```bash
docker-compose ps
```

Servicios disponibles:

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| Airflow UI | http://localhost:8080 | Interfaz de orquestaciÃ³n |
| Jupyter Lab | http://localhost:8888 | Notebooks de anÃ¡lisis |

### 5. Ejecutar el pipeline ETL

1. Abrir **Airflow UI** en http://localhost:8080
2. Localizar el DAG `monitor_precios_sipc_etl`
3. Activar el toggle (ON)
4. Hacer clic en â–¶ï¸ **Trigger DAG**

â±ï¸ **Tiempo de ejecuciÃ³n:** ~6 minutos

### 6. Verificar resultados

```bash
# Verificar datos generados
ls -la data_sipc/raw/
ls -la data_sipc/refined/
ls -la data_sipc/exports_dashboard/
```

### 7. Explorar notebooks

1. Obtener token de Jupyter:
   ```bash
   docker logs jupyter-spark 2>&1 | grep "token="
   ```
2. Abrir http://localhost:8888 con el token
3. Navegar a `notebooks/` y ejecutar en orden

### 8. Detener servicios

```bash
docker-compose down
```

---

## ðŸ”„ Pipeline ETL

### Flujo de datos

```
ðŸ“¥ Landing Zone (CSV)
    â†“ ingest_landing.py

ðŸ§¹ Raw Zone (Parquet)
    â†“ build_raw.py

ðŸ“ Refined Zone (Star Schema)
    â†“ build_dimensions.py â†’ dim_tiempo, dim_producto, 
    â”‚                       dim_establecimiento, dim_ubicacion
    â†“ build_facts.py â†’ fact_precios

ðŸ“Š Exports Dashboard
    â†“ simple_metrics.py â†’ 6 mÃ©tricas pre-calculadas
```

### Tareas del DAG

| Tarea | DescripciÃ³n | DuraciÃ³n aprox. |
|-------|-------------|-----------------|
| `ingest_landing` | Validar y copiar CSVs | 30s |
| `build_raw` | Limpiar y tipar datos | 2min |
| `build_dimensions` | Crear 4 dimensiones | 1min |
| `build_facts` | Crear tabla de hechos | 2min |
| `calculate_metrics` | Calcular 6 mÃ©tricas | 30s |

---

## ðŸ“ Modelo de Datos

### Star Schema

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   dim_tiempo    â”‚
                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                    â”‚ fecha_id (PK)   â”‚
                    â”‚ fecha, anio     â”‚
                    â”‚ mes, dia        â”‚
                    â”‚ trimestre       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  dim_producto   â”‚          â”‚          â”‚ dim_establecimiento â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚          â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ producto_id(PK) â”‚          â”‚          â”‚ establec_id (PK)    â”‚
â”‚ nombre, marca   â”‚          â”‚          â”‚ nombre, cadena      â”‚
â”‚ categoria       â”‚          â”‚          â”‚ razon_social        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                     â”‚
         â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
         â”‚         â”‚   fact_precios    â”‚           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ fecha_id (FK)     â”‚
                   â”‚ producto_id (FK)  â”‚
                   â”‚ establec_id (FK)  â”‚
                   â”‚ ubicacion_id (FK) â”‚
                   â”‚ precio, oferta    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  dim_ubicacion  â”‚
                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                    â”‚ ubicacion_id(PK)â”‚
                    â”‚ departamento    â”‚
                    â”‚ ciudad, barrio  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### EstadÃ­sticas del modelo

| Tabla | Registros | DescripciÃ³n |
|-------|-----------|-------------|
| `dim_tiempo` | ~365 | Atributos temporales |
| `dim_producto` | 379 | CatÃ¡logo de productos |
| `dim_establecimiento` | 852 | Puntos de venta |
| `dim_ubicacion` | 852 | InformaciÃ³n geogrÃ¡fica |
| `fact_precios` | 20M+ | Observaciones de precios |

---

## ðŸ“Š MÃ©tricas de Negocio

El proyecto calcula **6 mÃ©tricas principales**:

### 1. Precio Promedio por Producto
Promedio del precio agrupado por producto, aÃ±o y mes.

### 2. VariaciÃ³n Porcentual Mensual
Cambio porcentual del precio respecto al mes anterior:

```
VariaciÃ³n = (Precio actual - Precio anterior) / Precio anterior Ã— 100
```

### 3. Precio MÃ­nimo y MÃ¡ximo
Rango de precios por producto y perÃ­odo.

### 4. Costo de Canasta BÃ¡sica
Suma del costo de 62 productos de la canasta CBAEN 2024 por supermercado.

### 5. Ãndice de DispersiÃ³n
Variabilidad de precios entre establecimientos:

```
DispersiÃ³n = (Precio mÃ¡x - Precio mÃ­n) / Precio promedio
```

### 6. Ranking de Supermercados
Ordenamiento por costo total de canasta bÃ¡sica.

### Archivos de salida

```
data_sipc/exports_dashboard/
â”œâ”€â”€ precio_promedio.parquet
â”œâ”€â”€ variacion_mensual.parquet
â”œâ”€â”€ min_max_precios.parquet
â”œâ”€â”€ canasta_basica.parquet
â”œâ”€â”€ dispersion_precios.parquet
â””â”€â”€ ranking_supermercados.parquet
```

---

## ðŸ““ Notebooks

El proyecto incluye 3 notebooks interactivos:

| Notebook | DescripciÃ³n | DuraciÃ³n |
|----------|-------------|----------|
| `01_exploracion.ipynb` | AnÃ¡lisis exploratorio de datos raw | 10-15 min |
| `02_modelo_datos.ipynb` | DocumentaciÃ³n del Star Schema | 15-20 min |
| `03_dashboard.ipynb` | Dashboard con 6 mÃ©tricas y visualizaciones | 20-30 min |

### Orden de ejecuciÃ³n

```
01_exploracion â†’ 02_modelo_datos â†’ 03_dashboard
```

### Prerequisito

Los notebooks requieren que el pipeline ETL haya sido ejecutado previamente.

Ver documentaciÃ³n detallada en [`notebooks/README.md`](notebooks/README.md).

---

## ðŸ“‚ Estructura del Proyecto

```
monitor-precios-sipc/
â”œâ”€â”€ README.md                 # Este archivo
â”œâ”€â”€ docker-compose.yaml       # ConfiguraciÃ³n de servicios
â”œâ”€â”€ requirements.txt          # Dependencias Python
â”‚
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ Dockerfile            # Imagen custom con PySpark
â”‚   â”œâ”€â”€ entrypoint.sh
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ monitor_precios_dag.py  # DAG principal
â”‚   â””â”€â”€ logs/
â”‚
â”œâ”€â”€ src/                      # CÃ³digo fuente
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ ingest_landing.py
â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â”œâ”€â”€ build_raw.py
â”‚   â”‚   â”œâ”€â”€ build_dimensions.py
â”‚   â”‚   â””â”€â”€ build_facts.py
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â””â”€â”€ simple_metrics.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ spark_session.py
â”‚       â””â”€â”€ paths.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ 01_exploracion.ipynb
â”‚   â”œâ”€â”€ 02_modelo_datos.ipynb
â”‚   â””â”€â”€ 03_dashboard.ipynb
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ canasta_basica_cbaen_2024.md
â”‚   â””â”€â”€ metadata/
â”‚
â””â”€â”€ data_sipc/                # Data Lake (no versionado)
    â”œâ”€â”€ landing/
    â”œâ”€â”€ raw/
    â”œâ”€â”€ refined/
    â””â”€â”€ exports_dashboard/
```

---

## ðŸ”§ Desarrollo

### Modificar transformaciones

Los mÃ³dulos en `src/` estÃ¡n montados como volumen, los cambios se reflejan inmediatamente:

```bash
# Editar transformaciÃ³n
vim src/transform/build_dimensions.py

# Ejecutar DAG para probar cambios
# (desde Airflow UI o lÃ­nea de comandos)
```

### Comandos Ãºtiles

```bash
# Ver logs de Airflow
docker logs airflow --tail 100

# Acceder al contenedor
docker exec -it airflow bash

# Ejecutar DAG manualmente
docker exec airflow airflow dags trigger monitor_precios_sipc_etl

# Ver estado de ejecuciones
docker exec airflow airflow dags list-runs -d monitor_precios_sipc_etl

# Limpiar datos (reiniciar pipeline)
docker exec airflow rm -rf /opt/airflow/data_sipc/raw/* \
    /opt/airflow/data_sipc/refined/* \
    /opt/airflow/data_sipc/exports_dashboard/*
```

---

## ðŸ” SoluciÃ³n de Problemas

### Pipeline falla con "Permission denied"

```bash
# Corregir permisos del volumen
docker exec airflow chmod -R 777 /opt/airflow/data_sipc/
```

### Notebook muestra "FileNotFoundError"

**Causa:** Pipeline ETL no ejecutado.

```bash
# Ejecutar pipeline
docker exec airflow airflow dags trigger monitor_precios_sipc_etl

# Esperar ~6 minutos y verificar
ls -la data_sipc/exports_dashboard/
```

### Kernel de Jupyter muere

**Causa:** Memoria insuficiente.

**SoluciÃ³n:** Aumentar memoria en `docker-compose.yaml`:

```yaml
jupyter:
  deploy:
    resources:
      limits:
        memory: 6G
```

### Token de Jupyter no funciona

```bash
# Obtener nuevo token
docker logs jupyter-spark 2>&1 | grep "token="
```

---

## ðŸ“š Referencias

- **Datos:** [SIPC - CatÃ¡logo de Datos Abiertos Uruguay](https://catalogodatos.gub.uy/)
- **Canasta bÃ¡sica:** Informe CBAEN 2024 - Instituto Nacional de EstadÃ­stica (INE)
- **MetodologÃ­a:** [Kimball Dimensional Modeling](https://www.kimballgroup.com/)
- **PySpark:** [Apache Spark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)

---

## ðŸ‘¥ Autores

Proyecto desarrollado por **Ana Clara Sena**, **Francisco Lima** y **Mateo Rodriguez** para el curso **Big Data** â€“ UCU Campus Salto, Diciembre 2025.

---

## ðŸ“„ Licencia

Este proyecto es de uso acadÃ©mico.
