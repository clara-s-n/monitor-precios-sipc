# Monitor de Precios SIPC â€“ Obligatorio Big Data

Proyecto del curso **Big Data** (UCU â€“ Salto) que construye un **Data Lake** y un **pipeline ETL orquestado con Apache Airflow** para analizar los datos de precios del **SIPC** (Sistema de InformaciÃ³n de Precios al Consumidor).

## ğŸ¯ Objetivos

- Limpiar y unificar las tablas de precios, productos y establecimientos del SIPC
- Construir un **modelo tipo estrella** (dimensiones + hechos de precios)
- Calcular 6 mÃ©tricas clave sobre evoluciÃ³n de precios y canasta bÃ¡sica
- Exponer resultados en **dashboard Jupyter**

## ğŸ§© MÃ©tricas Implementadas

El proyecto calcula las siguientes **6 mÃ©tricas principales**:

1. **Precio promedio por producto**  
   Promedio del precio de un producto en un perÃ­odo y nivel de agregaciÃ³n determinado (por establecimiento, por cadena, por zona, etc.).  
   Ejemplo: precio promedio mensual del â€œArroz 1 kgâ€ por supermercado.

2. **VariaciÃ³n porcentual diaria/mensual**  
   Mide cuÃ¡nto variÃ³ el precio con respecto al perÃ­odo anterior.  
   FÃ³rmula genÃ©rica:  
   \[
   \text{VarPct} = \frac{\text{Precio actual} - \text{Precio anterior}}{\text{Precio anterior}}
   \]  
   Se calcula tanto **dÃ­a a dÃ­a** como **mes a mes** para productos y/o canasta.

3. **Precio mÃ­nimo y mÃ¡ximo**  
   Para cada producto y perÃ­odo, se calcula el **precio mÃ­nimo** y **mÃ¡ximo** observado entre todos los establecimientos.  
   Permite identificar supermercados mÃ¡s caros/baratos para cada producto.

4. **Costo de canasta bÃ¡sica por supermercado**  
   Se define una **canasta bÃ¡sica** como conjunto de productos seleccionados.  
   Para cada supermercado y perÃ­odo (por ejemplo, mes), se suma el precio de esos productos â†’ **costo total de la canasta**.  
   Permite comparar el â€œcosto de llenar el carritoâ€ entre supermercados.

5. **Ãndice de dispersiÃ³n de precios**  
   Mide cuÃ¡n dispersos estÃ¡n los precios de un producto entre establecimientos.  
   FÃ³rmula propuesta:  
   \[
   \text{Ãndice de dispersiÃ³n} = \frac{\text{Precio mÃ¡ximo} - \text{Precio mÃ­nimo}}{\text{Precio promedio}}
   \]  
   Valores altos indican gran diferencia de precios entre comercios.

6. **Ranking de supermercados segÃºn costo total**  
   A partir del costo de la canasta bÃ¡sica, se genera un ranking de supermercados (del mÃ¡s barato al mÃ¡s caro) para un perÃ­odo dado.  
   Puede filtrarse por ciudad/zona, cadena, etc.

Estas mÃ©tricas se calculan sobre la **capa Refined** del Data Lake y se utilizan en el dashboard final.

## ğŸ—ï¸ Arquitectura

### Data Lake (filesystem local)

```
data_sipc/
â”œâ”€â”€ landing/          # CSV originales del SIPC (no versionados)
â”œâ”€â”€ raw/              # Parquet limpio y tipado (PySpark)
â”œâ”€â”€ refined/          # Modelo estrella (dimensiones + hechos)
â””â”€â”€ exports_dashboard/ # Datasets finales para visualizaciÃ³n
```

### Stack TecnolÃ³gico

- **PySpark** (modo `local[*]`) â€“ Transformaciones ETL sin cluster distribuido
- **Apache Airflow 2.9.2** â€“ OrquestaciÃ³n (SequentialExecutor + SQLite)
- **Docker Compose** â€“ Contenedores `airflow` y `jupyter`
- **Parquet** â€“ Formato de almacenamiento optimizado

## ğŸš€ Inicio RÃ¡pido

### Prerequisitos

- Docker y Docker Compose instalados
- 4GB RAM disponible

### Levantar el entorno

```bash
# Clonar repositorio
git clone https://github.com/clara-s-n/monitor-precios-sipc.git
cd monitor-precios-sipc

# Iniciar servicios
docker-compose up -d

# Verificar estado
docker-compose ps
```

### Acceso a interfaces

| Servicio    | URL                   | Credenciales      |
| ----------- | --------------------- | ----------------- |
| Airflow UI  | http://localhost:8080 | Sin autenticaciÃ³n |
| Jupyter Lab | http://localhost:8888 | Token en logs     |

```bash
# Obtener token de Jupyter
docker logs jupyter-spark | grep "token="
```

### Ejecutar pipeline ETL

1. Colocar archivos CSV del SIPC en `data_sipc/landing/`:

   - `precios.csv`
   - `productos.csv`
   - `establecimientos.csv`

2. En Airflow UI (http://localhost:8080), activar DAG `monitor_precios_sipc_etl`

3. Monitorear ejecuciÃ³n en el panel de tareas

## ğŸ“‚ Estructura del Proyecto

```
monitor-precios-sipc/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ Dockerfile              # Imagen custom con PySpark
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ monitor_precios_dag.py  # âœ… OrquestaciÃ³n ETL principal
â”‚   â””â”€â”€ logs/                   # Logs de ejecuciÃ³n
â”‚
â”œâ”€â”€ src/                        # LÃ³gica de negocio (montado en containers)
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ ingest_landing.py   # âœ… ValidaciÃ³n y copia de CSVs
â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â”œâ”€â”€ build_raw.py        # âœ… Landing â†’ Raw (Parquet)
â”‚   â”‚   â”œâ”€â”€ build_dimensions.py # ConstrucciÃ³n de dimensiones
â”‚   â”‚   â””â”€â”€ build_facts.py      # Tabla de hechos
â”‚   â”œâ”€â”€ metrics/                # CÃ¡lculo de KPIs
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ spark_session.py    # âœ… Factory de sesiones Spark
â”‚       â””â”€â”€ paths.py            # âœ… GestiÃ³n de rutas del data lake
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploracion.ipynb    # AnÃ¡lisis exploratorio
â”‚   â”œâ”€â”€ 02_modelo_datos.ipynb   # DiseÃ±o star schema
â”‚   â””â”€â”€ 03_dashboard.ipynb      # Visualizaciones finales
â”‚
â”œâ”€â”€ data_sipc/                  # Data Lake (gitignored)
â””â”€â”€ docker-compose.yaml
```

âœ… = Implementado | ğŸ”² = Pendiente

## ğŸ“Š Pipeline ETL

### Flujo de datos

```
ğŸ“¥ Landing Zone (CSV)
    â†“ ingest_landing.py (validaciÃ³n + copia)

ğŸ§¹ Raw Zone (Parquet limpio)
    â†“ build_raw.py (limpieza + tipado)

ğŸ“ Refined Zone (Star Schema)
    â†“ build_dimensions.py
    â”‚   â†’ dim_tiempo, dim_producto, dim_establecimiento, dim_ubicacion
    â†“ build_facts.py
    â”‚   â†’ fact_precios

ğŸ“ˆ Exports Dashboard
    â†“ metrics/* (KPIs)
    â”‚   â†’ precio_promedio, dispersion_index, canasta_basica, ranking
```

### Modelo de Datos (Star Schema)

**Dimensiones:**

- `dim_tiempo`: fecha, aÃ±o, mes, dÃ­a, trimestre
- `dim_producto`: producto_id, nombre, categorÃ­a, subcategorÃ­a, marca
- `dim_establecimiento`: establecimiento_id, nombre, cadena
- `dim_ubicacion`: ubicacion_id, departamento, ciudad, direcciÃ³n

**Hechos:**

- `fact_precios`: precio, fecha_id, producto_id, establecimiento_id, ubicacion_id, unidad

## ğŸ”§ Desarrollo

### Editar transformaciones ETL
